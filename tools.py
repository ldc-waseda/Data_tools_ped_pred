from util import *
from data_loader import ETHLoader, SDDLoader
import pandas as pd
import io
import imageio
import cv2
import torch
import os
import matplotlib.pyplot as plt
import numpy as np

import sys, types, torch
class _SafePath(list):
    @property
    def _path(self):
        return self
fake_mod = types.ModuleType("torch.classes")
fake_mod.__path__ = _SafePath()
sys.modules["torch.classes"] = fake_mod

import streamlit as st

script_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.dirname(script_dir)

SDD_PATH = os.path.join(project_dir, 'sdd_dataset')
SDD_FILE = [
    'bookstore',
    'coupa',
    'deathCircle',
    'gates',
    'hyang',
    'little',
    'nexus',
    'quad',
]
ETH_PATH = os.path.join(project_dir, 'eth_dataset')
ETH_FILE = [
    'ETH',
    'HOTEL',
    'ZARA01',
    'ZARA02',
    'STUDENT',
]

sdd_datasets_txt_list, sdd_datasets_video_list = load_sdd_paths(SDD_PATH, SDD_FILE)
eth_datasets_txt_list, eth_datasets_video_list = load_eth_paths(ETH_PATH, ETH_FILE)

merged_txt_paths   = {**sdd_datasets_txt_list,  **eth_datasets_txt_list}
merged_video_paths = {**sdd_datasets_video_list,  **eth_datasets_video_list}
ALL_SCENES = ETH_FILE + SDD_FILE

st.sidebar.header('åœºæ™¯ä¸æ®µé€‰æ‹©')

# 1) é€‰æ‹©åœºæ™¯
scene = st.sidebar.selectbox('è¯·é€‰æ‹©åœºæ™¯', ALL_SCENES)

# ä»åˆå¹¶å­—å…¸ä¸­å–å‡ºè¯¥åœºæ™¯çš„æ‰€æœ‰ txt / video åˆ—è¡¨
txt_list = merged_txt_paths.get(scene, [])
vid_list = merged_video_paths.get(scene, [])

if not txt_list:
    st.sidebar.warning(f"åœºæ™¯ {scene} æœªæ‰¾åˆ°ä»»ä½• .txt æ–‡ä»¶")
if not vid_list:
    st.sidebar.warning(f"åœºæ™¯ {scene} æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")

# 2) å¦‚æœæ˜¯ SDD åœºæ™¯ï¼Œå†é€‰æ‹©å…·ä½“å“ªä¸ª segment
if scene in SDD_FILE:
    segments = sorted({os.path.basename(os.path.dirname(p)) for p in txt_list})
    segment = st.sidebar.selectbox('è¯·é€‰æ‹© Segment', segments)

    # è¿‡æ»¤å‡ºè¿™ä¸ª segment ä¸‹çš„æ–‡ä»¶
    txt_file = next(p for p in txt_list if os.path.basename(os.path.dirname(p)) == segment)
    vid_file = next(p for p in vid_list if os.path.basename(os.path.dirname(p)) == segment)

else:
    # ETH åœºæ™¯ï¼šç›´æ¥è®©ç”¨æˆ·ä»æ–‡ä»¶åˆ—è¡¨é‡Œé€‰ä¸€ä¸ª
    txt_file = st.sidebar.selectbox('æ ‡æ³¨æ–‡ä»¶ (.txt)', txt_list)
    vid_file = st.sidebar.selectbox('è§†é¢‘æ–‡ä»¶ (.avi/.mov)', vid_list)

# 3) åŠ è½½æ•°æ®
if scene in SDD_FILE:
    data_loader = SDDLoader(txt_file)
else:
    data_loader = ETHLoader(txt_file)

obs = torch.tensor(data_loader.target_obs, dtype=torch.float32)
obs.tag = data_loader.xy_tag
num_samples = obs.shape[0]


# ---------------------------------------------
# æ’å…¥ä½ç½®å»ºè®®ï¼šåœ¨ obs åŠ è½½å®Œæˆåï¼Œç´§æ¥ num_samples ä¹‹å
# ---------------------------------------------
st.sidebar.markdown("### å·¥å…·")

# è®¾ç½® SessionState key
session_key = f"unannotated_{scene}"
clear_key = f"clear_unannotated_{scene}"

# æ£€æµ‹æŒ‰é’®
if st.sidebar.button("ğŸ” æ£€æµ‹æœªæ ‡æ³¨æ ·æœ¬"):
    agent_ids = obs[:, 0, 1].int().numpy()
    dataset_name = "SDD" if scene in SDD_FILE else "ETH"
    sec_id = os.path.basename(os.path.dirname(txt_file)) if scene in SDD_FILE else scene

    expected_filenames = [
        f"{dataset_name}_{scene}_{sec_id}_{agent_id}.npz"
        for agent_id in agent_ids
    ]

    annotation_dir = "annotations_npz"
    existing_files = set(os.listdir(annotation_dir)) if os.path.exists(annotation_dir) else set()

    unannotated_indices = [
        idx for idx, fname in enumerate(expected_filenames)
        if fname not in existing_files
    ]

    st.session_state[session_key] = unannotated_indices

# å¯é€‰ï¼šæ¸…é™¤æŒ‰é’®
if st.sidebar.button("ğŸ§¹ æ¸…é™¤æ£€æµ‹ç»“æœ"):
    if session_key in st.session_state:
        del st.session_state[session_key]

# æ˜¾ç¤ºæ£€æµ‹ç»“æœï¼ˆå¦‚æœå­˜åœ¨ï¼‰
if session_key in st.session_state:
    st.markdown("### â—ï¸æœªæ ‡æ³¨æ ·æœ¬æ£€æµ‹ç»“æœ")
    unannotated_indices = st.session_state[session_key]
    if unannotated_indices:
        st.warning(f"å½“å‰åœºæ™¯ä¸‹å…±æœ‰ {len(unannotated_indices)} ä¸ªæ ·æœ¬æœªè¢«æ ‡æ³¨")
        st.code(unannotated_indices, language='python')
    else:
        st.success("æ‰€æœ‰æ ·æœ¬å‡å·²æ ‡æ³¨ âœ…")




st.write(
    f"### å½“å‰åœºæ™¯ï¼š**{scene}**"
    + (f" / Segment **{segment}**" if scene in SDD_FILE else "")
    + (f"  Total NUM **{num_samples}**")
)
if num_samples == 0:
    st.warning("è¯¥åœºæ™¯æ— å¯ç”¨æ ·æœ¬")
    st.stop()

# 4.1) åœ¨ä¾§è¾¹æ é€‰æ‹©å½“å‰æ ·æœ¬ç´¢å¼•
sample_idx = st.sidebar.number_input(
    "é€‰æ‹©æ ·æœ¬ç´¢å¼•",
    min_value=0,
    max_value=num_samples - 1,
    value=0,
    step=1,
    format="%d"
)

# 4.1.1) ğŸ‘‰ ç«‹åˆ»æ”¾ä¸€ä¸ªâ€œä¿å­˜æ ·æœ¬æ•°æ®â€æŒ‰é’®ï¼Œè®°å½•ç‚¹å‡»ç»“æœ
save_btn_clicked = st.sidebar.button(
    "ä¿å­˜æ ·æœ¬æ•°æ®",
    key=f"save_npz_{scene}_{sample_idx}"
)


# 4.2) æå–è¯¥æ ·æœ¬çš„æ•°æ®ï¼šframes, id, xy
sample = obs[sample_idx]            # shape [frames, feat_dim]
frames = sample[:, 0].long().numpy()
agent_id = int(sample[0, 1].item())
if obs.tag == 0:
    traj = sample[:, [3, 2]].numpy()   # shape [frames, 2]
else:
    traj = sample[:, [2, 3]].numpy()   # shape [frames, 2]

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# æ–°å¢ï¼šè®¡ç®—è§‚æµ‹åºåˆ—ä¸é¢„æµ‹åºåˆ—çš„å¹³å‡é€Ÿåº¦
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
obs_len = 8
pred_len = 12

total_len = traj.shape[0]
use_obs_len = min(obs_len, total_len)
use_pred_len = min(pred_len, total_len - use_obs_len)

obs_traj = traj[:use_obs_len]
pred_traj = traj[use_obs_len:use_obs_len + use_pred_len]

def compute_avg_speed(sequence):
    if sequence.shape[0] < 2:
        return 0.0
    diffs = sequence[1:] - sequence[:-1]
    dists = np.linalg.norm(diffs, axis=1)
    return float(dists.mean())

avg_speed_obs  = compute_avg_speed(obs_traj)
avg_speed_pred = compute_avg_speed(pred_traj)

# å°†æ•°å€¼è½¬æˆå¸¦ä¸¤ä½å°æ•°çš„å­—ç¬¦ä¸²
obs_speed_str  = f"{avg_speed_obs:.2f} px/frame"
pred_speed_str = f"{avg_speed_pred:.2f} px/frame"
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ä¿®æ”¹ï¼šå°†â€œé€Ÿåº¦â€æ æ”¹ä¸ºè‡ªåŠ¨å¡«å……è§‚æµ‹/é¢„æµ‹æ®µå¹³å‡é€Ÿåº¦ï¼Œ
#        åªä¿ç•™â€œç¨‹åº¦â€å’Œâ€œæ–¹å‘â€çš„æ‰‹åŠ¨é€‰æ‹©
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# å®šä¹‰â€œç¨‹åº¦â€å’Œâ€œæ–¹å‘â€å…³é”®è¯
keywords2 = ["slight", "extreme"]
keywords3 = [
    "forward", "left-forward", "right-forward",
    "left", "right", "back",
    "left-back", "right-back"
]

default_index2 = ([""] + keywords2).index("slight") if "slight" in keywords2 else 0
default_index3 = ([""] + keywords3).index("forward") if "forward" in keywords3 else 0

# å•ä¸€ annotation key
annotation_key = f"ann_{scene}_{sample_idx}"
if annotation_key not in st.session_state:
    st.session_state[annotation_key] = ""

# å·¦ä¾§ï¼šè§‚æµ‹éƒ¨åˆ†ï¼ˆæ˜¾ç¤ºè‡ªåŠ¨é€Ÿåº¦ï¼Œæ‰‹åŠ¨ç¨‹åº¦ä¸æ–¹å‘ï¼‰
st.sidebar.markdown("## è§‚æµ‹åºåˆ—æ ‡ç­¾ï¼ˆredï¼‰")
st.sidebar.write(f"**è‡ªåŠ¨é€Ÿåº¦ï¼š** {obs_speed_str} (åƒç´ /å¸§)")

obs_degree    = st.sidebar.selectbox("1ï¸âƒ£ ç¨‹åº¦", [""] + keywords2, key=f"{annotation_key}_obs_degree", index=default_index2)
obs_direction = st.sidebar.selectbox("2ï¸âƒ£ æ–¹å‘", [""] + keywords3, key=f"{annotation_key}_obs_direction", index=default_index3)

# å·¦ä¾§ï¼šé¢„æµ‹éƒ¨åˆ†
st.sidebar.markdown("---")
st.sidebar.markdown("## é¢„æµ‹åºåˆ—æ ‡ç­¾ï¼ˆgreenï¼‰")
st.sidebar.write(f"**è‡ªåŠ¨é€Ÿåº¦ï¼š** {pred_speed_str} (åƒç´ /å¸§)")

pred_degree    = st.sidebar.selectbox("1ï¸âƒ£ ç¨‹åº¦", [""] + keywords2, key=f"{annotation_key}_pred_degree", index=default_index2)
pred_direction = st.sidebar.selectbox("2ï¸âƒ£ æ–¹å‘", [""] + keywords3, key=f"{annotation_key}_pred_direction", index=default_index3)
pred_confidence = st.sidebar.selectbox(
    "3ï¸âƒ£ ç½®ä¿¡åº¦ (yes/no)",
    ["yes", "no"],
    key=f"{annotation_key}_pred_confidence"
)
st.sidebar.markdown("---")

# åªè¦å››é¡¹éƒ½éç©ºï¼Œå°±è‡ªåŠ¨æ‹¼æ¥
if (
    obs_degree and obs_direction
    and pred_degree and pred_direction
):
    filled = (
        f"a person go {{{obs_speed_str}}} {{{obs_degree}}} {{{obs_direction}}} "
        f"then {{{pred_speed_str}}} {{{pred_degree}}} {{{pred_direction}}}"
    )
    if st.session_state[annotation_key] != filled:
        st.session_state[annotation_key] = filled

# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
# ç»“æŸâ€œä¿®æ”¹éƒ¨åˆ†â€
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# 4.3) å±•ç¤ºæ ·æœ¬åŸºæœ¬ä¿¡æ¯
st.write(f"**æ ·æœ¬ {sample_idx}** â€” Agent ID: {agent_id} â€” é•¿åº¦: {len(frames)} å¸§")
st.write(f"- è§‚æµ‹æ®µå¹³å‡é€Ÿåº¦ (åƒç´ /å¸§)ï¼š**{avg_speed_obs:.2f}**")
st.write(f"- é¢„æµ‹æ®µå¹³å‡é€Ÿåº¦ (åƒç´ /å¸§)ï¼š**{avg_speed_pred:.2f}**")

# 4.4) è¯»å–èµ·å§‹å¸§å¹¶ä½œèƒŒæ™¯å›¾
st.subheader("Ped View")
cap = cv2.VideoCapture(vid_file)
cap.set(cv2.CAP_PROP_POS_FRAMES, int(frames[0]))
ret, frame = cap.read()
cap.release()

if ret:
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    fig, ax = plt.subplots(figsize=(4, 4))
    ax.imshow(frame_rgb)
    traj_int = traj.astype(int)

    # ç»˜åˆ¶è§‚æµ‹æ®µï¼ˆçº¢è‰²ï¼‰å’Œé¢„æµ‹æ®µï¼ˆç»¿è‰²ï¼‰
    first_pts = traj_int[:use_obs_len]
    ax.plot(
        first_pts[:, 0], first_pts[:, 1],
        '-o', color='red',
        markersize=4, linewidth=2,
    )
    second_pts = traj_int[use_obs_len:use_obs_len + use_pred_len]
    ax.plot(
        second_pts[:, 0], second_pts[:, 1],
        '-o', color='green',
        markersize=4, linewidth=2,
    )

    # åœ¨å›¾ä¸Šæ ‡æ³¨å¹³å‡é€Ÿåº¦
    ax.text(
        5, 15,
        f"Obs avg: {avg_speed_obs:.2f}",
        color='white', fontsize=10,
        bbox=dict(facecolor='red', alpha=0.5, pad=2)
    )
    ax.text(
        5, 55,
        f"Pred avg: {avg_speed_pred:.2f}",
        color='white', fontsize=10,
        bbox=dict(facecolor='green', alpha=0.5, pad=2)
    )

    ax.set_title(f"Global View of Ped: {agent_id} from Frame: {frames[0]}")
    ax.axis('off')
    # ax.legend(loc='lower right', fontsize=8)
    st.pyplot(fig)
else:
    st.warning(f"æ— æ³•è¯»å–å¸§ {frames[0]}ï¼Œæ— æ³•å¯è§†åŒ–è½¨è¿¹")

# 4.5) è¯»å–æ‰€æœ‰å¸§ï¼Œå åŠ è½¨è¿¹ï¼Œç”Ÿæˆ GIF
st.subheader("GIF å¯è§†åŒ–")
gif_container = st.empty()

def make_gif_bytes(images):
    buf = io.BytesIO()
    with imageio.get_writer(buf, format='GIF', mode='I', fps=5) as writer:
        for img in images:
            writer.append_data(img)
    buf.seek(0)
    return buf.read()

cap = cv2.VideoCapture(vid_file)
traj_int = traj.astype(int)
images_rgb = []
for idx, t in enumerate(frames):
    cap.set(cv2.CAP_PROP_POS_FRAMES, int(t))
    ret, frame = cap.read()
    if not ret:
        continue
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    p = tuple(traj_int[idx])
    cv2.circle(frame_rgb, p, radius=15, color=(0, 0, 255), thickness=-1)
    images_rgb.append(frame_rgb)
cap.release()

# åˆæ¬¡ç”Ÿæˆå¹¶å±•ç¤º GIF
gif_bytes = make_gif_bytes(images_rgb)
gif_container.image(gif_bytes, caption="å½“å‰ç‚¹åŠ¨ç”» (GIF)", use_container_width=True)

if st.button("Replay"):
    gif_bytes = make_gif_bytes(images_rgb)
    gif_container.image(gif_bytes, caption="å½“å‰ç‚¹åŠ¨ç”» (GIF)", use_container_width=True)

# 4.6) åœ¨ä¸»åŒºåŸŸå±•ç¤ºå•å¥æ³¨é‡Šï¼Œç”¨æˆ·å¯æ‰‹åŠ¨å¾®è°ƒ
st.markdown("### æ³¨é‡Š (Observation â†’ Prediction)")
st.text_area(
    "è‡ªåŠ¨æ‹¼æ¥å¹¶å¯ç¼–è¾‘ï¼š",
    value=st.session_state[annotation_key],
    key=annotation_key,
    height=80
)


# 4.7) ä¿å­˜æŒ‰é’® â€”â€” æ”¹ä¸ºæ£€æµ‹ save_btn_clicked
if save_btn_clicked:
    # 1) è®¡ç®— sec_id
    if scene in SDD_FILE:
        sec_id = os.path.basename(os.path.dirname(txt_file))
    else:
        sec_id = scene
    pred_confidence = st.session_state.get(f"{annotation_key}_pred_confidence", "")
    print(pred_confidence)
    # 2) å‡†å¤‡è¦ä¿å­˜çš„å­—å…¸
    data_dict = {
        "id":          np.int32(agent_id),
        "start_frame": np.int32(frames[0]),
        "total_seq":   np.int32(len(frames)),
        "traj":        traj.astype(np.float32),
        "start_img":   images_rgb[0].astype(np.uint8),
        "annotation":  np.array(st.session_state[annotation_key], dtype="U"),
        "avg_speed_obs":  np.float32(avg_speed_obs),
        "avg_speed_pred": np.float32(avg_speed_pred),
        "pred_confidence": np.array(pred_confidence, dtype="U")
    }
    # 3) æ–‡ä»¶å & ä¿å­˜
    dataset_name = "SDD" if scene in SDD_FILE else "ETH"
    filename = f"{dataset_name}_{scene}_{sec_id}_{agent_id}.npz"
    os.makedirs("annotations_npz", exist_ok=True)
    save_path = os.path.join("annotations_npz", filename)
    np.savez_compressed(save_path, **data_dict)
    st.sidebar.success(f"å·²ä¿å­˜ â†’ {save_path}")



# # 4.7) ä¿å­˜æŒ‰é’®
# if st.sidebar.button("ä¿å­˜æ ·æœ¬æ•°æ®", key=f"save_npz_{scene}_{sample_idx}"):
#     # 1) è®¡ç®— sec_id
#     if scene in SDD_FILE:
#         sec_id = os.path.basename(os.path.dirname(txt_file))
#     else:
#         sec_id = scene
#     pred_confidence = st.session_state.get(f"{annotation_key}_pred_confidence", "")
#     print(pred_confidence)
#     # 2) å‡†å¤‡è¦ä¿å­˜çš„å­—å…¸
#     data_dict = {
#         "id":          np.int32(agent_id),
#         "start_frame": np.int32(frames[0]),
#         "total_seq":   np.int32(len(frames)),
#         "traj":        traj.astype(np.float32),
#         "start_img":   images_rgb[0].astype(np.uint8),
#         "annotation":  np.array(st.session_state[annotation_key], dtype="U"),
#         "avg_speed_obs":  np.float32(avg_speed_obs),
#         "avg_speed_pred": np.float32(avg_speed_pred),
#         "pred_confidence": np.array(pred_confidence, dtype="U")
#     }
#     # 3) æ–‡ä»¶å & ä¿å­˜
#     dataset_name = "SDD" if scene in SDD_FILE else "ETH"
#     filename = f"{dataset_name}_{scene}_{sec_id}_{agent_id}.npz"
#     os.makedirs("annotations_npz", exist_ok=True)
#     save_path = os.path.join("annotations_npz", filename)
#     np.savez_compressed(save_path, **data_dict)

#     st.sidebar.success(f"å·²ä¿å­˜ â†’ {save_path}")
